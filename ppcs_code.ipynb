{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, recall_score, precision_score, accuracy_score\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import neurokit2 as nk\n",
    "import hrvanalysis as hrv\n",
    "from scipy import ndimage\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFECV\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Data preprocessing and feature extraction\n",
    "\n",
    "folder_path = '/home/mw/input/hfindex7735/vol1/PPC'\n",
    "npz_files = [os.path.join(root, file) for root, _, files in os.walk(folder_path) for file in files if file.endswith('.npz')]\n",
    "ecg = []\n",
    "rsp = []\n",
    "spo = []\n",
    "acc = []\n",
    "for i, file_path in enumerate(npz_files):\n",
    "    data = np.load(file_path)\n",
    "    ecg.append(data['ecg_list'])\n",
    "    rsp.append(data['rsp_list'])\n",
    "    spo.append(data['spo_value'])\n",
    "    acc.append(data['acc'])\n",
    "\n",
    "\n",
    "ecg_raw = ecg\n",
    "rsp_raw = rsp\n",
    "spo_raw = spo\n",
    "acc_raw = acc\n",
    "\n",
    "def smooth_signal(signal, size):\n",
    "    smoothed_signal = np.zeros(len(signal))\n",
    "    for i in np.arange(len(signal)):\n",
    "        if i == 0:\n",
    "            smoothed_signal[i] = signal[i]\n",
    "        elif i < np.divide((size - 1), 2):\n",
    "            smoothed_signal[i] = np.mean(signal[:i * 2 + 1])\n",
    "        elif i > len(signal) - np.divide((size - 1), 2) - 1:\n",
    "            smoothed_signal[i] = np.mean(signal[i - (len(signal) - 1 - i):len(signal)])\n",
    "        else:\n",
    "            start = int(i - np.divide((size - 1), 2))\n",
    "            end = int(i + 1 + np.divide((size - 1), 2))\n",
    "            smoothed_signal[i] = np.mean(signal[start:end])\n",
    "    return smoothed_signal\n",
    "\n",
    "\n",
    "def remove_outliers(signal, size):\n",
    "\n",
    "    for i in np.arange(size, len(signal) - size):\n",
    "        mean = np.mean(np.hstack((signal[i-size:i],signal[i+1:i+size+1])))\n",
    "        std = np.std(np.hstack((signal[i-size:i],signal[i+1:i+size+1])))\n",
    "        if ((signal[i] > mean + 3*std) | (signal[i] < mean - 3*std)):\n",
    "            signal[i] = mean\n",
    "    return signal\n",
    "\n",
    "# smooth:\n",
    "ecg_smoothed = smooth_signal(ecg_raw, size=200)\n",
    "rsp_smoothed = smooth_signal(rsp_raw, size=25)\n",
    "spo_smoothed = smooth_signal(spo_raw, size=10)\n",
    "acc_smoothed = smooth_signal(acc_raw, size=10)\n",
    "\n",
    "#Removing outliers\n",
    "ecg_remove = remove_outliers(ecg_smoothed, size=200)\n",
    "rsp_remove = remove_outliers(rsp_smoothed, size=25)\n",
    "spo_remove = remove_outliers(spo_smoothed, size=10)\n",
    "acc_remove = remove_outliers(acc_smoothed, size=10)\n",
    "\n",
    "_, results = nk.ecg_peaks(ecg_remove, sampling_rate=200, method='Hamilton')\n",
    "nn = results['ECG_R_Peaks']\n",
    "\n",
    "# HRV features\n",
    "hrv_feature = hrv.extract_features.get_time_domain_features(nn_intervals=nn)\n",
    "hrv_feature2 = hrv.extract_features.get_frequency_domain_features(nn_intervals)\n",
    "\n",
    "# Characterization of the arrhythmic load\n",
    "ar_burden = rr_process(ecg_remove)\n",
    "\n",
    "# Respiratory characteristics\n",
    "rsp_info = nk.rsp_findpeaks(rsp_cleaned=rsp_remove, sampling_rate=25, method=\"khodadad2018\")\n",
    "rsp_feature = rsp_process(rsp_info)\n",
    "\n",
    "# Oxygen Characteristics\n",
    "spo_feature = spo_process(spo_remove)\n",
    "\n",
    "# Sleep features\n",
    "slp_features = sleep_process(ecg_remove, rsp_remove, spo_remove)\n",
    "\n",
    "# Merge\n",
    "Physiology_features = hrv_feature.merge(hrv_feature2, on='key', how='inner') \\\n",
    "    .merge(ar_burden, on='key', how='inner') \\\n",
    "    .merge(rsp_feature, on='key', how='inner') \\\n",
    "    .merge(spo_feature, on='key', how='inner') \\\n",
    "    .merge(slp_features, on='key', how='inner')\n",
    "\n",
    "# clinical\n",
    "clinical_features = pd.read_csv('clinical_data.csv')\n",
    "\n",
    "all_features = pd.merge(Physiology_features, clinical_features, on='key', how='inner')\n",
    "\n",
    "with pd.ExcelWriter('Physiological and Clinical Characteristics of Heart valve surgery patients.xlsx') as writer:\n",
    "    clinical_features.to_excel(writer, sheet_name='cln', index=False)\n",
    "    Physiology_features.to_excel(writer, sheet_name='phy', index=False)\n",
    "    all_features.to_excel(writer, sheet_name='both', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature screening\n",
    "\n",
    "excel_file_path = 'Physiological and Clinical Characteristics of Heart valve surgery patients.xlsx'\n",
    "\n",
    "\n",
    "#Choose a different learner\n",
    "models_dict = {\n",
    "    \"XGBoost\": XGBClassifier(learning_rate=0.01, n_estimators=10, max_depth=1, random_state=1),\n",
    "    \"Logistic Regression\": LogisticRegression(C=0.01, random_state=1),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=10, max_depth=1, random_state=1),\n",
    "    \"SVM\": SVC(kernel='linear', random_state=1, probability=True),\n",
    "    \"KNN\": KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "sheets = ['cln', 'phy', 'both']\n",
    "models = ['XGBoost', 'Logistic Regression', 'Random Forest', 'SVM', 'KNN']\n",
    "\n",
    "#Stored in the corresponding model sheet\n",
    "with pd.ExcelWriter('Feature screened _data.xlsx') as writer:\n",
    "  \n",
    "    for model_name in models:\n",
    "        estimator = models_dict[model_name]  \n",
    "        \n",
    "\n",
    "        for sheet in sheets:\n",
    "            print(f\"Processing data for model , sheet {sheet}\")\n",
    "\n",
    "            df = pd.read_excel(excel_file_path, sheet_name=sheet)\n",
    "            X = df.iloc[:, :-1].values \n",
    "            y = df.iloc[:, -1].values  \n",
    "\n",
    "            rfecv = RFECV(estimator=estimator, step=1, cv=StratifiedKFold(5), scoring='roc_auc')\n",
    "            rfecv.fit(X, y)\n",
    "\n",
    "            print(f\"Optimal number of features for {model_name} on {sheet}: {rfecv.n_features_}\")\n",
    "            print(f\"Ranking of features for {model_name} on {sheet}: {rfecv.ranking_}\")\n",
    "\n",
    "            selected_features = df.columns[:-1][rfecv.support_]\n",
    "            processed_data = df[selected_features]               \n",
    "            processed_data['Label'] = y                         \n",
    "\n",
    "            output_sheet_name = f\"{model_name}_{sheet}\"\n",
    "            processed_data.to_excel(writer, sheet_name=output_sheet_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model tuning\n",
    "\n",
    "excel_file_path = 'Feature screened _data.xlsx'\n",
    "\n",
    "# Define the model and corresponding sheet names\n",
    "# cln for clinical data, phy for physiologic data, both for total data\n",
    "sheet_mapping = {\n",
    "    \"XGBoost\": [\"xgb_cln\", \"xgb_phy\", \"xgb_both\"],\n",
    "    \"Logistic Regression\": [\"lr_cln\", \"lr_phy\", \"lr_both\"],\n",
    "    \"Random Forest\": [\"rf_cln\", \"rf_phy\", \"rf_both\"],\n",
    "    \"SVM\": [\"svm_cln\", \"svm_phy\", \"svm_both\"],\n",
    "    \"KNN\": [\"knn_cln\", \"knn_phy\", \"knn_both\"]\n",
    "}\n",
    "\n",
    "# Define initial parameters for each model\n",
    "models = {\n",
    "    \"XGBoost\": xgb.XGBClassifier(learning_rate=0.01, n_estimators=10, max_depth=1, random_state=1),\n",
    "    \"Logistic Regression\": LogisticRegression(C=0.01, random_state=1),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=10, max_depth=1, random_state=1),\n",
    "    \"SVM\": SVC(kernel='poly', C=0.01, random_state=1, probability=True),\n",
    "    \"KNN\": KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grids = {\n",
    "    \"XGBoost\": {\n",
    "        'n_estimators': list(range(10, 101, 10)),\n",
    "        'max_depth': list(range(1, 10)),\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'random_state' : list(range(1,50))\n",
    "    },\n",
    "    \"Logistic Regression\": {\n",
    "        'C': [0.01, 0.1, 0.2, 0.5, 1, 10]\n",
    "        'random_state' : list(range(1,50))\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        'n_estimators': [10, 40, 70, 100],\n",
    "        'max_depth': [1, 2, 4, 6, 8]\n",
    "        'random_state' : list(range(1,50))\n",
    "    },\n",
    "    \"SVM\": {\n",
    "        'C': [0.01, 0.1, 0.2, 0.5, 1],\n",
    "        'kernel': ['linear', 'poly', 'rbf']\n",
    "        'random_state' : list(range(1,50))\n",
    "    },\n",
    "    \"KNN\": {\n",
    "        'n_neighbors': [3, 5, 7, 9],\n",
    "        'weights': ['uniform', 'distance']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Read and process the corresponding sheet for each model and perform parameter search, training and evaluation\n",
    "for model_name, sheets in sheet_mapping.items():\n",
    "    model = models[model_name]\n",
    "    print(f\"processing: {model_name}\")\n",
    "    \n",
    "\n",
    "    for sheet in sheets:\n",
    "        print(f\" data: {sheet}\")\n",
    "        \n",
    "        df = pd.read_excel(excel_file_path, sheet_name=sheet)\n",
    "        all_features = df.values\n",
    "        X = all_features[:, :-1] \n",
    "        y = all_features[:, -1]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "\n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=param_grids[model_name],\n",
    "                                   scoring='roc_auc', cv=5, n_jobs=-1)\n",
    "        \n",
    "\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        print(f\" Best parameters found: {grid_search.best_params_}\")\n",
    "        print(f\" Best AUC score: {grid_search.best_score_}\")\n",
    "        \n",
    "\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "        test_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        print(f\" Test AUC score:: {test_auc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Model training\n",
    "\n",
    "models = {\n",
    "    \"XGBoost\": xgb.XGBClassifier(learning_rate=0.1, n_estimators=32, max_depth=1, random_state=30),\n",
    "    \"Logistic Regression\": LogisticRegression(C=0.2, random_state=1),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=40, max_depth=2, random_state=1),\n",
    "    \"SVM\": SVC(kernel='poly', C=0.2, random_state=10, probability=True),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "}\n",
    "\n",
    "sheet_mapping = {\n",
    "    \"XGBoost\": [\"xgb_cln\", \"xgb_phy\", \"xgb_both\"],\n",
    "    \"Logistic Regression\": [\"lr_cln\", \"lr_phy\", \"lr_both\"],\n",
    "    \"Random Forest\": [\"rf_cln\", \"rf_phy\", \"rf_both\"],\n",
    "    \"SVM\": [\"svm_cln\", \"svm_phy\", \"svm_both\"],\n",
    "    \"KNN\": [\"knn_cln\", \"knn_phy\", \"knn_both\"]\n",
    "}\n",
    "\n",
    "results = {}\n",
    "predictions = {model_name: [] for model_name in models.keys()}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    a_auc_per_sheet = []  # Store the AUC value for each sheet\n",
    "    for sheet in sheet_mapping[model_name]:\n",
    "        df = pd.read_excel('Feature screened _data.xlsx', sheet_name=sheet)\n",
    "        X = df.iloc[:, :-1]\n",
    "        y = df.iloc[:, -1]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "        #5-fold cross validation\n",
    "        skf = StratifiedKFold(n_splits=5, random_state=10, shuffle=True) \n",
    "        a_auc, a_acc, a_f1, a_pre = [], [], [], []\n",
    "        sheet_predictions = []\n",
    "\n",
    "        for tr_idx, test_idx in skf.split(X, y):\n",
    "            lab = y\n",
    "            model.fit(X[tr_idx], y[tr_idx])\n",
    "            y_predict = model.predict_proba(X[test_idx])[:, -1] \n",
    "            sheet_predictions.extend(y_predict)  \n",
    "            aauc = roc_auc_score(y[test_idx], y_predict)\n",
    "            f1_s = f1_score(lab[test_idx.tolist()], predict)\n",
    "            prec = precision_score(lab[test_idx.tolist()], predict)\n",
    "            aauc = roc_auc_score(lab[test_idx.tolist()], y_predict[:, -1])\n",
    "            a_auc.append(aauc)\n",
    "            a_acc.append(acc)\n",
    "            a_f1.append(f1_s)\n",
    "            a_pre.append(prec)\n",
    "        mean_auc = np.mean(a_auc)\n",
    "        a_auc_per_sheet.append(mean_auc)\n",
    "        predictions[model_name].append(np.array(sheet_predictions))  \n",
    "        results[model_name] = a_auc_per_sheet\n",
    "        print(f \"{model_name}:\")\n",
    "        \n",
    "        #Calculation of auc,acc,f1\n",
    "        print(round(np.mean(a_auc), 2), '±', round(np.std(a_auc, ddof=1), 2))\n",
    "        print(round(np.mean(a_acc), 2), '±', round(np.std(a_acc, ddof=1), 2))\n",
    "        print(round(np.mean(a_f1), 2), '±', round(np.std(a_f1, ddof=1), 2))\n",
    "        print(round(np.mean(a_pre), 2), '±', round(np.std(a_pre, ddof=1), 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
